{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import argparse, time, logging, os, sys, math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import gluoncv as gcv\n",
    "from mxnet import gluon, nd, init, context\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from gluoncv.data.transforms import video\n",
    "from gluoncv.data import VideoClsCustom\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21083, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"metadata.csv\")\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>fps</th>\n",
       "      <th>gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5579</th>\n",
       "      <td>57653</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5580</th>\n",
       "      <td>69502</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5581</th>\n",
       "      <td>68796</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>57664</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>66598</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>57655</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>57665</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>57666</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>57658</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>57659</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>70017</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>68236</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>27180</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>67755</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>27181</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>27182</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>27183</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6501</th>\n",
       "      <td>27184</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>27173</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>34118</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8470</th>\n",
       "      <td>34123</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>34124</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>34127</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>34128</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>34129</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>34121</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>34137</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  fps  gloss\n",
       "5579     57653   25      2\n",
       "5580     69502   25      2\n",
       "5581     68796   25      2\n",
       "5583     57664   25      2\n",
       "5584     66598   25      2\n",
       "5585     57655   25      2\n",
       "5586     57665   25      2\n",
       "5587     57666   25      2\n",
       "5591     57658   25      2\n",
       "5592     57659   25      2\n",
       "6494     70017   25      0\n",
       "6495     68236   25      0\n",
       "6496     27180   25      0\n",
       "6497     67755   25      0\n",
       "6498     27181   25      0\n",
       "6499     27182   25      0\n",
       "6500     27183   25      0\n",
       "6501     27184   25      0\n",
       "6503     27173   25      0\n",
       "8469     34118   25      1\n",
       "8470     34123   25      1\n",
       "8471     34124   25      1\n",
       "8473     34127   25      1\n",
       "8474     34128   25      1\n",
       "8475     34129   25      1\n",
       "8476     34121   25      1\n",
       "8480     34137   25      1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array(['hello', 'love', 'thank you'])\n",
    "train_txt = metadata[(metadata['gloss'].isin(actions)) & (metadata['split'] == 'train')][['video_id', 'fps', 'gloss']]#.unique()\n",
    "#train_txt['video_id'] = train_txt['video_id'].astype(str) + '.mp4'\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "train_txt = train_txt.replace({\"gloss\": label_map})\n",
    "train_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt.to_csv(r'train.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_txt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 27 training samples.\n"
     ]
    }
   ],
   "source": [
    "num_gpus = 0\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "transform_train = video.VideoGroupTrainTransform(size=(224, 224), scale_ratios=[1.0, 0.8], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "per_device_batch_size = 5\n",
    "num_workers = 0\n",
    "batch_size = per_device_batch_size * num_gpus\n",
    "\n",
    "train_dataset = VideoClsCustom(root=os.path.expanduser('~\\\\Sign-Language-Translator\\\\videos'),\n",
    "                               setting=os.path.expanduser('~\\\\Sign-Language-Translator\\\\notebooks\\\\train.txt'),\n",
    "                               train=True,\n",
    "                               #new_length=32,\n",
    "                               transform=transform_train)\n",
    "print('Load %d training samples.' % len(train_dataset))\n",
    "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                   shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv24_weight is done with shape:  (64, 3, 5, 7, 7)\n",
      "batchnorm24_gamma is done with shape:  (64,)\n",
      "batchnorm24_beta is done with shape:  (64,)\n",
      "batchnorm24_running_mean is done with shape:  (64,)\n",
      "batchnorm24_running_var is done with shape:  (64,)\n",
      "layer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\n",
      "layer1_0_batchnorm0_gamma is done with shape:  (64,)\n",
      "layer1_0_batchnorm0_beta is done with shape:  (64,)\n",
      "layer1_0_batchnorm0_running_mean is done with shape:  (64,)\n",
      "layer1_0_batchnorm0_running_var is done with shape:  (64,)\n",
      "layer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
      "layer1_0_batchnorm1_gamma is done with shape:  (64,)\n",
      "layer1_0_batchnorm1_beta is done with shape:  (64,)\n",
      "layer1_0_batchnorm1_running_mean is done with shape:  (64,)\n",
      "layer1_0_batchnorm1_running_var is done with shape:  (64,)\n",
      "layer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
      "layer1_0_batchnorm2_gamma is done with shape:  (256,)\n",
      "layer1_0_batchnorm2_beta is done with shape:  (256,)\n",
      "layer1_0_batchnorm2_running_mean is done with shape:  (256,)\n",
      "layer1_0_batchnorm2_running_var is done with shape:  (256,)\n",
      "layer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\n",
      "layer1_downsample_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer1_downsample_batchnorm0_beta is done with shape:  (256,)\n",
      "layer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer1_downsample_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
      "layer1_1_batchnorm0_gamma is done with shape:  (64,)\n",
      "layer1_1_batchnorm0_beta is done with shape:  (64,)\n",
      "layer1_1_batchnorm0_running_mean is done with shape:  (64,)\n",
      "layer1_1_batchnorm0_running_var is done with shape:  (64,)\n",
      "layer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
      "layer1_1_batchnorm1_gamma is done with shape:  (64,)\n",
      "layer1_1_batchnorm1_beta is done with shape:  (64,)\n",
      "layer1_1_batchnorm1_running_mean is done with shape:  (64,)\n",
      "layer1_1_batchnorm1_running_var is done with shape:  (64,)\n",
      "layer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
      "layer1_1_batchnorm2_gamma is done with shape:  (256,)\n",
      "layer1_1_batchnorm2_beta is done with shape:  (256,)\n",
      "layer1_1_batchnorm2_running_mean is done with shape:  (256,)\n",
      "layer1_1_batchnorm2_running_var is done with shape:  (256,)\n",
      "layer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
      "layer1_2_batchnorm0_gamma is done with shape:  (64,)\n",
      "layer1_2_batchnorm0_beta is done with shape:  (64,)\n",
      "layer1_2_batchnorm0_running_mean is done with shape:  (64,)\n",
      "layer1_2_batchnorm0_running_var is done with shape:  (64,)\n",
      "layer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
      "layer1_2_batchnorm1_gamma is done with shape:  (64,)\n",
      "layer1_2_batchnorm1_beta is done with shape:  (64,)\n",
      "layer1_2_batchnorm1_running_mean is done with shape:  (64,)\n",
      "layer1_2_batchnorm1_running_var is done with shape:  (64,)\n",
      "layer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
      "layer1_2_batchnorm2_gamma is done with shape:  (256,)\n",
      "layer1_2_batchnorm2_beta is done with shape:  (256,)\n",
      "layer1_2_batchnorm2_running_mean is done with shape:  (256,)\n",
      "layer1_2_batchnorm2_running_var is done with shape:  (256,)\n",
      "layer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\n",
      "layer2_0_batchnorm0_gamma is done with shape:  (128,)\n",
      "layer2_0_batchnorm0_beta is done with shape:  (128,)\n",
      "layer2_0_batchnorm0_running_mean is done with shape:  (128,)\n",
      "layer2_0_batchnorm0_running_var is done with shape:  (128,)\n",
      "layer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
      "layer2_0_batchnorm1_gamma is done with shape:  (128,)\n",
      "layer2_0_batchnorm1_beta is done with shape:  (128,)\n",
      "layer2_0_batchnorm1_running_mean is done with shape:  (128,)\n",
      "layer2_0_batchnorm1_running_var is done with shape:  (128,)\n",
      "layer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
      "layer2_0_batchnorm2_gamma is done with shape:  (512,)\n",
      "layer2_0_batchnorm2_beta is done with shape:  (512,)\n",
      "layer2_0_batchnorm2_running_mean is done with shape:  (512,)\n",
      "layer2_0_batchnorm2_running_var is done with shape:  (512,)\n",
      "layer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\n",
      "layer2_downsample_batchnorm0_gamma is done with shape:  (512,)\n",
      "layer2_downsample_batchnorm0_beta is done with shape:  (512,)\n",
      "layer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\n",
      "layer2_downsample_batchnorm0_running_var is done with shape:  (512,)\n",
      "layer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
      "layer2_1_batchnorm0_gamma is done with shape:  (128,)\n",
      "layer2_1_batchnorm0_beta is done with shape:  (128,)\n",
      "layer2_1_batchnorm0_running_mean is done with shape:  (128,)\n",
      "layer2_1_batchnorm0_running_var is done with shape:  (128,)\n",
      "layer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
      "layer2_1_batchnorm1_gamma is done with shape:  (128,)\n",
      "layer2_1_batchnorm1_beta is done with shape:  (128,)\n",
      "layer2_1_batchnorm1_running_mean is done with shape:  (128,)\n",
      "layer2_1_batchnorm1_running_var is done with shape:  (128,)\n",
      "layer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
      "layer2_1_batchnorm2_gamma is done with shape:  (512,)\n",
      "layer2_1_batchnorm2_beta is done with shape:  (512,)\n",
      "layer2_1_batchnorm2_running_mean is done with shape:  (512,)\n",
      "layer2_1_batchnorm2_running_var is done with shape:  (512,)\n",
      "layer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\n",
      "layer2_2_batchnorm0_gamma is done with shape:  (128,)\n",
      "layer2_2_batchnorm0_beta is done with shape:  (128,)\n",
      "layer2_2_batchnorm0_running_mean is done with shape:  (128,)\n",
      "layer2_2_batchnorm0_running_var is done with shape:  (128,)\n",
      "layer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
      "layer2_2_batchnorm1_gamma is done with shape:  (128,)\n",
      "layer2_2_batchnorm1_beta is done with shape:  (128,)\n",
      "layer2_2_batchnorm1_running_mean is done with shape:  (128,)\n",
      "layer2_2_batchnorm1_running_var is done with shape:  (128,)\n",
      "layer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
      "layer2_2_batchnorm2_gamma is done with shape:  (512,)\n",
      "layer2_2_batchnorm2_beta is done with shape:  (512,)\n",
      "layer2_2_batchnorm2_running_mean is done with shape:  (512,)\n",
      "layer2_2_batchnorm2_running_var is done with shape:  (512,)\n",
      "layer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
      "layer2_3_batchnorm0_gamma is done with shape:  (128,)\n",
      "layer2_3_batchnorm0_beta is done with shape:  (128,)\n",
      "layer2_3_batchnorm0_running_mean is done with shape:  (128,)\n",
      "layer2_3_batchnorm0_running_var is done with shape:  (128,)\n",
      "layer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
      "layer2_3_batchnorm1_gamma is done with shape:  (128,)\n",
      "layer2_3_batchnorm1_beta is done with shape:  (128,)\n",
      "layer2_3_batchnorm1_running_mean is done with shape:  (128,)\n",
      "layer2_3_batchnorm1_running_var is done with shape:  (128,)\n",
      "layer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
      "layer2_3_batchnorm2_gamma is done with shape:  (512,)\n",
      "layer2_3_batchnorm2_beta is done with shape:  (512,)\n",
      "layer2_3_batchnorm2_running_mean is done with shape:  (512,)\n",
      "layer2_3_batchnorm2_running_var is done with shape:  (512,)\n",
      "layer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\n",
      "layer3_0_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_0_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_0_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_0_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_0_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_0_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_0_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_0_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_0_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_0_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_0_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_0_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\n",
      "layer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\n",
      "layer3_downsample_batchnorm0_beta is done with shape:  (1024,)\n",
      "layer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\n",
      "layer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\n",
      "layer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
      "layer3_1_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_1_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_1_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_1_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_1_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_1_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_1_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_1_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_1_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_1_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_1_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_1_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
      "layer3_2_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_2_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_2_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_2_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_2_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_2_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_2_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_2_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_2_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_2_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_2_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_2_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
      "layer3_3_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_3_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_3_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_3_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_3_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_3_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_3_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_3_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_3_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_3_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_3_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_3_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
      "layer3_4_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_4_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_4_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_4_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_4_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_4_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_4_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_4_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_4_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_4_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_4_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_4_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
      "layer3_5_batchnorm0_gamma is done with shape:  (256,)\n",
      "layer3_5_batchnorm0_beta is done with shape:  (256,)\n",
      "layer3_5_batchnorm0_running_mean is done with shape:  (256,)\n",
      "layer3_5_batchnorm0_running_var is done with shape:  (256,)\n",
      "layer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
      "layer3_5_batchnorm1_gamma is done with shape:  (256,)\n",
      "layer3_5_batchnorm1_beta is done with shape:  (256,)\n",
      "layer3_5_batchnorm1_running_mean is done with shape:  (256,)\n",
      "layer3_5_batchnorm1_running_var is done with shape:  (256,)\n",
      "layer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
      "layer3_5_batchnorm2_gamma is done with shape:  (1024,)\n",
      "layer3_5_batchnorm2_beta is done with shape:  (1024,)\n",
      "layer3_5_batchnorm2_running_mean is done with shape:  (1024,)\n",
      "layer3_5_batchnorm2_running_var is done with shape:  (1024,)\n",
      "layer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\n",
      "layer4_0_batchnorm0_gamma is done with shape:  (512,)\n",
      "layer4_0_batchnorm0_beta is done with shape:  (512,)\n",
      "layer4_0_batchnorm0_running_mean is done with shape:  (512,)\n",
      "layer4_0_batchnorm0_running_var is done with shape:  (512,)\n",
      "layer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
      "layer4_0_batchnorm1_gamma is done with shape:  (512,)\n",
      "layer4_0_batchnorm1_beta is done with shape:  (512,)\n",
      "layer4_0_batchnorm1_running_mean is done with shape:  (512,)\n",
      "layer4_0_batchnorm1_running_var is done with shape:  (512,)\n",
      "layer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
      "layer4_0_batchnorm2_gamma is done with shape:  (2048,)\n",
      "layer4_0_batchnorm2_beta is done with shape:  (2048,)\n",
      "layer4_0_batchnorm2_running_mean is done with shape:  (2048,)\n",
      "layer4_0_batchnorm2_running_var is done with shape:  (2048,)\n",
      "layer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\n",
      "layer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\n",
      "layer4_downsample_batchnorm0_beta is done with shape:  (2048,)\n",
      "layer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\n",
      "layer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\n",
      "layer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\n",
      "layer4_1_batchnorm0_gamma is done with shape:  (512,)\n",
      "layer4_1_batchnorm0_beta is done with shape:  (512,)\n",
      "layer4_1_batchnorm0_running_mean is done with shape:  (512,)\n",
      "layer4_1_batchnorm0_running_var is done with shape:  (512,)\n",
      "layer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
      "layer4_1_batchnorm1_gamma is done with shape:  (512,)\n",
      "layer4_1_batchnorm1_beta is done with shape:  (512,)\n",
      "layer4_1_batchnorm1_running_mean is done with shape:  (512,)\n",
      "layer4_1_batchnorm1_running_var is done with shape:  (512,)\n",
      "layer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
      "layer4_1_batchnorm2_gamma is done with shape:  (2048,)\n",
      "layer4_1_batchnorm2_beta is done with shape:  (2048,)\n",
      "layer4_1_batchnorm2_running_mean is done with shape:  (2048,)\n",
      "layer4_1_batchnorm2_running_var is done with shape:  (2048,)\n",
      "layer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\n",
      "layer4_2_batchnorm0_gamma is done with shape:  (512,)\n",
      "layer4_2_batchnorm0_beta is done with shape:  (512,)\n",
      "layer4_2_batchnorm0_running_mean is done with shape:  (512,)\n",
      "layer4_2_batchnorm0_running_var is done with shape:  (512,)\n",
      "layer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
      "layer4_2_batchnorm1_gamma is done with shape:  (512,)\n",
      "layer4_2_batchnorm1_beta is done with shape:  (512,)\n",
      "layer4_2_batchnorm1_running_mean is done with shape:  (512,)\n",
      "layer4_2_batchnorm1_running_var is done with shape:  (512,)\n",
      "layer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
      "layer4_2_batchnorm2_gamma is done with shape:  (2048,)\n",
      "layer4_2_batchnorm2_beta is done with shape:  (2048,)\n",
      "layer4_2_batchnorm2_running_mean is done with shape:  (2048,)\n",
      "layer4_2_batchnorm2_running_var is done with shape:  (2048,)\n",
      "dense24_weight is skipped with shape:  (3, 2048)\n",
      "dense24_bias is skipped with shape:  (3,)\n",
      "I3D_ResNetV1(\n",
      "  (first_stage): HybridSequential(\n",
      "    (0): Conv3D(3 -> 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "    (2): Activation(relu)\n",
      "    (3): MaxPool3D(size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
      "  )\n",
      "  (pool2): MaxPool3D(size=(2, 1, 1), stride=(2, 1, 1), padding=(0, 0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
      "  (res_layers): HybridSequential(\n",
      "    (0): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=256)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=512)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=2048)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (st_avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
      "  (head): HybridSequential(\n",
      "    (0): Dropout(p = 0.8, axes=())\n",
      "    (1): Dense(2048 -> 3, linear)\n",
      "  )\n",
      "  (fc): Dense(2048 -> 3, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = get_model(name='i3d_resnet50_v1_custom', nclass=3)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate decay factor\n",
    "lr_decay = 0.1\n",
    "# Epochs where learning rate decays\n",
    "lr_decay_epoch = [40, 80, 100]\n",
    "\n",
    "# Stochastic gradient descent\n",
    "optimizer = 'sgd'\n",
    "# Set parameters\n",
    "optimizer_params = {'learning_rate': 0.001, 'wd': 0.0001, 'momentum': 0.9}\n",
    "\n",
    "# Define our trainer for net\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metric = mx.metric.Accuracy()\n",
    "train_history = TrainingHistory(['training-acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not load file C:\\Users\\rbcor\\Sign-Language-Translator\\videos\\34128\\img_00008.jpg starting at frame 8. Check data path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_data):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, batch)\n",
      "File \u001b[1;32mc:\\Users\\rbcor\\Sign-Language-Translator\\venv\\lib\\site-packages\\mxnet\\gluon\\data\\dataloader.py:635\u001b[0m, in \u001b[0;36mDataLoader.__iter__.<locals>.same_process_iter\u001b[1;34m()\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msame_process_iter\u001b[39m():\n\u001b[0;32m    634\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_sampler:\n\u001b[1;32m--> 635\u001b[0m         ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batchify_fn([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m batch])\n\u001b[0;32m    636\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    637\u001b[0m             ret \u001b[39m=\u001b[39m _as_in_context(ret, context\u001b[39m.\u001b[39mcpu_pinned(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_device_id))\n",
      "File \u001b[1;32mc:\\Users\\rbcor\\Sign-Language-Translator\\venv\\lib\\site-packages\\mxnet\\gluon\\data\\dataloader.py:635\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msame_process_iter\u001b[39m():\n\u001b[0;32m    634\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_sampler:\n\u001b[1;32m--> 635\u001b[0m         ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batchify_fn([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m batch])\n\u001b[0;32m    636\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    637\u001b[0m             ret \u001b[39m=\u001b[39m _as_in_context(ret, context\u001b[39m.\u001b[39mcpu_pinned(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_device_id))\n",
      "File \u001b[1;32mc:\\Users\\rbcor\\Sign-Language-Translator\\venv\\lib\\site-packages\\gluoncv\\data\\video_custom\\classification.py:194\u001b[0m, in \u001b[0;36mVideoClsCustom.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    192\u001b[0m         clip_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_slowfast_cv2_loader(directory, duration, segment_indices, skip_offsets)\n\u001b[0;32m    193\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m         clip_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_image_TSN_cv2_loader(directory, duration, segment_indices, skip_offsets)\n\u001b[0;32m    196\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     clip_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(clip_input)\n",
      "File \u001b[1;32mc:\\Users\\rbcor\\Sign-Language-Translator\\venv\\lib\\site-packages\\gluoncv\\data\\video_custom\\classification.py:308\u001b[0m, in \u001b[0;36mVideoClsCustom._image_TSN_cv2_loader\u001b[1;34m(self, directory, duration, indices, skip_offsets)\u001b[0m\n\u001b[0;32m    306\u001b[0m cv_img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2\u001b[39m.\u001b[39mimread(frame_path)\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m cv_img \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mraise\u001b[39;00m(\u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not load file \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m starting at frame \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. Check data path.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (frame_path, offset)))\n\u001b[0;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_width \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_height \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    310\u001b[0m     h, w, _ \u001b[39m=\u001b[39m cv_img\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not load file C:\\Users\\rbcor\\Sign-Language-Translator\\videos\\34128\\img_00008.jpg starting at frame 8. Check data path."
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_data):\n",
    "    print(i, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not load file C:\\Users\\rbcor\\Sign-Language-Translator\\videos\\66598.mp4\\img_00011.jpg starting at frame 11. Check data path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [102], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     lr_decay_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Loop through each batch of training data\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_data):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Extract data and label\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     data \u001b[38;5;241m=\u001b[39m split_and_load(batch[\u001b[38;5;241m0\u001b[39m], ctx_list\u001b[38;5;241m=\u001b[39mctx, batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m     label \u001b[38;5;241m=\u001b[39m split_and_load(batch[\u001b[38;5;241m1\u001b[39m], ctx_list\u001b[38;5;241m=\u001b[39mctx, batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rbcor\\Sign-Language-Translator\\venv\\lib\\site-packages\\mxnet\\gluon\\data\\dataloader.py:635\u001b[0m, in \u001b[0;36mDataLoader.__iter__.<locals>.same_process_iter\u001b[1;34m()\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msame_process_iter\u001b[39m():\n\u001b[0;32m    634\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_sampler:\n\u001b[1;32m--> 635\u001b[0m         ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batchify_fn([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m batch])\n\u001b[0;32m    636\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    637\u001b[0m             ret \u001b[39m=\u001b[39m _as_in_context(ret, context\u001b[39m.\u001b[39mcpu_pinned(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_device_id))\n",
      "File \u001b[1;32mc:\\Users\\rbcor\\Sign-Language-Translator\\venv\\lib\\site-packages\\mxnet\\gluon\\data\\dataloader.py:635\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msame_process_iter\u001b[39m():\n\u001b[0;32m    634\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_sampler:\n\u001b[1;32m--> 635\u001b[0m         ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batchify_fn([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m batch])\n\u001b[0;32m    636\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    637\u001b[0m             ret \u001b[39m=\u001b[39m _as_in_context(ret, context\u001b[39m.\u001b[39mcpu_pinned(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_device_id))\n",
      "File \u001b[1;32mc:\\Users\\rbcor\\Sign-Language-Translator\\venv\\lib\\site-packages\\gluoncv\\data\\video_custom\\classification.py:194\u001b[0m, in \u001b[0;36mVideoClsCustom.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    192\u001b[0m         clip_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_slowfast_cv2_loader(directory, duration, segment_indices, skip_offsets)\n\u001b[0;32m    193\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m         clip_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_image_TSN_cv2_loader(directory, duration, segment_indices, skip_offsets)\n\u001b[0;32m    196\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     clip_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(clip_input)\n",
      "File \u001b[1;32mc:\\Users\\rbcor\\Sign-Language-Translator\\venv\\lib\\site-packages\\gluoncv\\data\\video_custom\\classification.py:308\u001b[0m, in \u001b[0;36mVideoClsCustom._image_TSN_cv2_loader\u001b[1;34m(self, directory, duration, indices, skip_offsets)\u001b[0m\n\u001b[0;32m    306\u001b[0m cv_img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2\u001b[39m.\u001b[39mimread(frame_path)\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m cv_img \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mraise\u001b[39;00m(\u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not load file \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m starting at frame \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. Check data path.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (frame_path, offset)))\n\u001b[0;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_width \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_height \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    310\u001b[0m     h, w, _ \u001b[39m=\u001b[39m cv_img\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not load file C:\\Users\\rbcor\\Sign-Language-Translator\\videos\\66598.mp4\\img_00011.jpg starting at frame 11. Check data path."
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "lr_decay_count = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    train_metric.reset()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Learning rate decay\n",
    "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
    "        lr_decay_count += 1\n",
    "\n",
    "    # Loop through each batch of training data\n",
    "    for i, batch in enumerate(train_data):\n",
    "        # Extract data and label\n",
    "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "\n",
    "        # AutoGrad\n",
    "        with ag.record():\n",
    "            output = []\n",
    "            for _, X in enumerate(data):\n",
    "                X = X.reshape((-1,) + X.shape[2:])\n",
    "                pred = net(X)\n",
    "                output.append(pred)\n",
    "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
    "\n",
    "        # Backpropagation\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        # Optimize\n",
    "        trainer.step(batch_size)\n",
    "\n",
    "        # Update metrics\n",
    "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
    "        train_metric.update(label, output)\n",
    "\n",
    "        if i == 100:\n",
    "            break\n",
    "\n",
    "    name, acc = train_metric.get()\n",
    "\n",
    "    # Update history and print metrics\n",
    "    train_history.update([acc])\n",
    "    print('[Epoch %d] train=%f loss=%f time: %f' %\n",
    "        (epoch, acc, train_loss / (i+1), time.time()-tic))\n",
    "\n",
    "# We can plot the metric scores with:\n",
    "train_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fea2f75e32e174d7ae5c5f56d5e78c273eabdf215c4982af77b58664ffedf85f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
